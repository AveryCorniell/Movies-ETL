# Movies-ETL  
## Overview of Data Analysis for Amazing Prime Videos Hackathon  

The purpose of this analysis is to prepare data for a hackathon that will  
enable them to create an algorithm to determine which low budget films will  
become popular so they can buy the movie rights.  

The following resources were used to Extract, Transform, and Load data:  
- Data Sources: Wikipedia Movies JSON file, Kaggle Metadata  
- Software - Open Source: Python 3.9 - Jupyter Notebook; Postgresql - PGAdmin  

## Cleaned Data Results  
-  Movie Data  
	- 32 columns  
	- 6,051 rows of data


![Movies_Columns](https://user-images.githubusercontent.com/83401820/129549126-03cc3f13-2753-4701-9fc7-47d89188bf1c.png)  

![movies_query](https://user-images.githubusercontent.com/83401820/129549185-6c548e92-a2d6-4c6d-bf97-8b2799c374fe.png)  

- Ratings Data  
	- 5 columns  
	- 26,024,289 rows of data  

![Ratings_Columns](https://user-images.githubusercontent.com/83401820/129549123-d1c5dfa5-1602-463c-9642-7bfe601fcb9f.png)  

![ratings_query](https://user-images.githubusercontent.com/83401820/129549184-c063f5dc-3298-425b-8a55-3d8ca84d056d.png)  

## Summary  
- Using the cleaned data that has been loaded into PostgreSQL database, hackathon participants are able to  
easily retrieve, parse, and manipulate data through code to complete the challenge and possibly become the  
next winner of the hackathon challenge.  
- Clean usable data will significantly reduce the participants' time developing and debugging code, and since  
most hackathons are on time constraints, this was a much needed process  

### LET'S GET HACKING!

  



  


